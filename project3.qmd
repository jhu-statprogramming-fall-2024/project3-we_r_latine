---
title: "project3"
format: html
editor: visual
---

## Project 3

Team Members:

-   Mateo Bandala Jacques \| abandal1\@jh.edu

-   María Camila Restrepo \| mrestre\@jh.edu

# Setup

```{r}

library(tidyverse)
library(caret)
library(nycflights13)
library(car)
library(Metrics)



```

::: callout-note
## For our project, we will be using the NYY flights data
:::

# Part 1

Tu parte aquí belleza:

```{r}

#We will be using flight data from nycflight13



```

# Part 2

```{r}

nyc_flights <- flights

#Add weather!
nyc_flights <- flights %>%
  left_join(weather, by = c("year", "month", "day", "hour", "origin"))

#Our outcome of interest will be "ARRIVAL DELAY"

#Let's look at a simple boxplot of arrival delay
nyc_flights %>%
  filter(!is.na(arr_delay)) %>%
  slice_sample(n=1000)%>%
  ggplot(aes(x=arr_delay)) +
  scale_x_continuous(limits = c(0,200)) +
  geom_vline(xintercept = 30, color="red")+  #Maybe we could consider a cut-ff of 30 if we decide to go binary
  geom_bar() +
  labs(x="Departure delay", y="Count", title = "Histogram of arrival delay",
       subtitle = "NYC, 2013", caption = "Random sample of 1,000 flights")


#First, split the data into training and testing set

#Set seed
set.seed(89631139) 


#Keep only those rows with outcome data (arrival delay)
nyc_flights <- nyc_flights %>% filter(!is.na(arr_delay))

# Create partition indices (7 to 3)


train_index <- createDataPartition(nyc_flights$arr_delay, p = 0.7, list = FALSE)

# Split the data
train_data <- nyc_flights[train_index, ]
test_data <- nyc_flights[-train_index, ]

dim(train_data)
dim(test_data) #Looks good 





```
::: callout-note
## First, we will select which predictors to include by using Recursive Feature Elimination
:::


```{r}

#Let's use linear model, 5k crossvalidation
control <- rfeControl(functions = lmFuncs, method = "cv", number = 5)

# Perform RFE using some prespecified predictors
#Departure delay (obvious), distance,  Temperature, precipitation, and  wind speed

rfe_results <- rfe(
  train_data[, c("dep_delay", "distance", "temp", "precip", "wind_speed")], # Predictors
  train_data$arr_delay,                                # Outcome
  sizes = c(1:5),                                      # Test with 1 up to 5 predictors
  rfeControl = control #using linear regression with 5-fold cross validation
)

# View the optimal predictors
print(rfe_results)  #Using all 5 predictors has the lowest mean squared errors

# Plot RFE results

rfe_results %>%
  ggplot() +
  labs(x="Number of variables", y = "RMSE by CV",
       title = "Results of RFE", subtitle = "Using linear regression with 5 fold CV",
       caption  = "Model favours using all 5 variables")




```
::: callout-note
## Now let's train the model
:::

```{r}
#these are our optimal variables: 
optimal_predictors <- rfe_results$optVariables


#Let's fir a linear regression
formula <- as.formula(paste("arr_delay ~", paste(optimal_predictors, collapse = " + ")))
lm_model <- lm(formula, data = train_data)

#Let's look at the model output

summary(lm_model)

vif(lm_model) #There seems to be no issues with colinearity 




#Let's test the model

#First evaluate missingness
test_data %>%
  summarise(across(
    all_of(c("arr_delay", "dep_delay", "distance", "temp", "precip", "wind_speed")), 
    ~ sum(is.na(.)), 
    .names = "missing_{.col}"
  ))

# A small porportion of predictors are missingm we will simply get rid of them for now
test_data <- test_data %>%
  filter(if_all(
    all_of(c("arr_delay", "dep_delay", "distance", "temp", "precip", "wind_speed")), 
    ~ !is.na(.)
  ))

#now the prediction proper 

test_predictions <- predict(lm_model, newdata = test_data)




# Evaluate model performance

rmse_value <- rmse(test_data$arr_delay, test_predictions)
mae_value <- mae(test_data$arr_delay, test_predictions)
r_squared <- cor(test_data$arr_delay, test_predictions)^2

# Print metrics
cat("RMSE:", rmse_value, "\n") #this was 17.84 in the training set
cat("MAE:", mae_value, "\n")  #This was13 in the trainign set 
cat("R-squared:", r_squared, "\n") #this was 84 in the training set



ggplot(data = test_data, aes(x = test_predictions, y = arr_delay)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  ggtitle("Actual vs Predicted Arrival Delays") +
  xlab("Predicted Arrival Delay") +
  ylab("Actual Arrival Delay")


```

